---
layout: post
title: "Named Entity Recognition and Pattern Matching - TradeOffs Part 2"
---

Math
======================

Last time, I talked about the purpose of Named Entity Recognition and some high level 

cases of where it's used and the intuition behind it. Next is the math behind it and

why it works. In general, I will be describing how maximum likelihood estimates

are calculated for sequences of tokens relative to different features in the tokens.

These include things like part of speech tags, word is capital letter, ends with a period..


Overview
=========================

First, we need to understand sequence classifiers. Sequence classifers at a high level

can be described as follows.

Given a set of tokens (t_i...t_k...t_n) label a subset of tokens t_j...t_k

such that the chunk idenfifies some pattern in the text (NER) according to

the following probability distribution:


Let t_0 denote the current token's label, and w denote a given word in the sequence, then a sequence classifier's probability distribution is:

P(t_0 | t_i-1,w_0)



Markov Networks
================================================

A Markov Network is a directed graph such that each node is a random variable in a joint probability distribution.

Typically, a markov network is compiled by deciding on random variables (features described in the previous blog post).

A few different search algorithms can then be used to estimate the most likely sequence given the present nodes

and their links.

Worth mentioning here are a few different algorithms:

     1. Virterbi Algorithm
     2. LBFGS
     3. Quazi Newton Methods
     4. Stochastic gradident ascent/descent

The general idea with each of these algorithms is to find some target local minima/maxima

to discover the most likely sequence in the network.



Hidden Markov Models
===============================

A Hidden Markov Model is a model such that a node i's probablility is only affected by the 

previous node.



Conditional Random Fields
=========================================


Different types of conditional random fields:




Maximum Entropy Sequence Models
=============================================




Supplementary Resources
====================================